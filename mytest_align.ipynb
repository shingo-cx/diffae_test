{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df0f20bb-7587-45a3-9238-caa5b8001305",
   "metadata": {},
   "source": [
    "## 画像の前処理にあたるalignmentをする用\n",
    "使う画像は全部これやる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "402d5f0a-4444-400d-a0f5-44bbf44f79f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import bz2\n",
    "import os\n",
    "import os.path as osp\n",
    "import sys\n",
    "import cv2\n",
    "\n",
    "import dlib\n",
    "import numpy as np\n",
    "import PIL.Image\n",
    "import requests\n",
    "import scipy.ndimage\n",
    "from tqdm import tqdm\n",
    "\n",
    "LANDMARKS_MODEL_URL = 'http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0982e7-68af-42b1-8e67-6f271577cf4c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### align"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6bf0c73-f169-42dd-91f0-a8358542811d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LandmarksDetector:\n",
    "    def __init__(self, predictor_model_path):\n",
    "        \"\"\"\n",
    "        :param predictor_model_path: path to shape_predictor_68_face_landmarks.dat file\n",
    "        \"\"\"\n",
    "        self.detector = dlib.get_frontal_face_detector(\n",
    "        )  # cnn_face_detection_model_v1 also can be used\n",
    "        self.shape_predictor = dlib.shape_predictor(predictor_model_path)\n",
    "\n",
    "    def get_landmarks(self, image):\n",
    "        # img = cv2.imread(image)\n",
    "        # img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        img = dlib.load_rgb_image(image)\n",
    "        dets = self.detector(img, 1)\n",
    "\n",
    "        for detection in dets:\n",
    "            face_landmarks = [\n",
    "                (item.x, item.y)\n",
    "                for item in self.shape_predictor(img, detection).parts()\n",
    "            ]\n",
    "            yield face_landmarks\n",
    "\n",
    "\n",
    "def unpack_bz2(src_path):\n",
    "    dst_path = src_path[:-4]\n",
    "    if os.path.exists(dst_path):\n",
    "        print('cached')\n",
    "        return dst_path\n",
    "    data = bz2.BZ2File(src_path).read()\n",
    "    with open(dst_path, 'wb') as fp:\n",
    "        fp.write(data)\n",
    "    return dst_path\n",
    "\n",
    "\n",
    "def work_landmark(raw_img_path, img_name, face_landmarks):\n",
    "    face_img_name = '%s.png' % (os.path.splitext(img_name)[0], )\n",
    "    aligned_face_path = os.path.join(ALIGNED_IMAGES_DIR, face_img_name)\n",
    "    if os.path.exists(aligned_face_path):\n",
    "        return\n",
    "    image_align(raw_img_path,\n",
    "                aligned_face_path,\n",
    "                face_landmarks,\n",
    "                output_size=256)\n",
    "\n",
    "\n",
    "def get_file(src, tgt):\n",
    "    if os.path.exists(tgt):\n",
    "        print('cached')\n",
    "        return tgt\n",
    "    tgt_dir = os.path.dirname(tgt)\n",
    "    if not os.path.exists(tgt_dir):\n",
    "        os.makedirs(tgt_dir)\n",
    "    file = requests.get(src)\n",
    "    open(tgt, 'wb').write(file.content)\n",
    "    return tgt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1004978e-3a41-4787-90a4-1486e2c08a81",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def image_align(src_file,\n",
    "                dst_file,\n",
    "                face_landmarks,\n",
    "                output_size=1024,\n",
    "                transform_size=4096,\n",
    "                enable_padding=True):\n",
    "    # Align function from FFHQ dataset pre-processing step\n",
    "    # https://github.com/NVlabs/ffhq-dataset/blob/master/download_ffhq.py\n",
    "\n",
    "    lm = np.array(face_landmarks)\n",
    "    lm_chin = lm[0:17]  # left-right\n",
    "    lm_eyebrow_left = lm[17:22]  # left-right\n",
    "    lm_eyebrow_right = lm[22:27]  # left-right\n",
    "    lm_nose = lm[27:31]  # top-down\n",
    "    lm_nostrils = lm[31:36]  # top-down\n",
    "    lm_eye_left = lm[36:42]  # left-clockwise\n",
    "    lm_eye_right = lm[42:48]  # left-clockwise\n",
    "    lm_mouth_outer = lm[48:60]  # left-clockwise\n",
    "    lm_mouth_inner = lm[60:68]  # left-clockwise\n",
    "\n",
    "    # Calculate auxiliary vectors.\n",
    "    eye_left = np.mean(lm_eye_left, axis=0)\n",
    "    eye_right = np.mean(lm_eye_right, axis=0)\n",
    "    eye_avg = (eye_left + eye_right) * 0.5\n",
    "    eye_to_eye = eye_right - eye_left\n",
    "    mouth_left = lm_mouth_outer[0]\n",
    "    mouth_right = lm_mouth_outer[6]\n",
    "    mouth_avg = (mouth_left + mouth_right) * 0.5\n",
    "    eye_to_mouth = mouth_avg - eye_avg\n",
    "\n",
    "    # Choose oriented crop rectangle.\n",
    "    x = eye_to_eye - np.flipud(eye_to_mouth) * [-1, 1]\n",
    "    x /= np.hypot(*x)\n",
    "    x *= max(np.hypot(*eye_to_eye) * 2.0, np.hypot(*eye_to_mouth) * 1.8)\n",
    "    y = np.flipud(x) * [-1, 1]\n",
    "    c = eye_avg + eye_to_mouth * 0.1\n",
    "    quad = np.stack([c - x - y, c - x + y, c + x + y, c + x - y])\n",
    "    qsize = np.hypot(*x) * 2\n",
    "\n",
    "    # Load in-the-wild image.\n",
    "    if not os.path.isfile(src_file):\n",
    "        print(\n",
    "            '\\nCannot find source image. Please run \"--wilds\" before \"--align\".'\n",
    "        )\n",
    "        return\n",
    "    img = PIL.Image.open(src_file)\n",
    "    img = img.convert('RGB')\n",
    "\n",
    "    # Shrink.\n",
    "    shrink = int(np.floor(qsize / output_size * 0.5))\n",
    "    if shrink > 1:\n",
    "        rsize = (int(np.rint(float(img.size[0]) / shrink)),\n",
    "                 int(np.rint(float(img.size[1]) / shrink)))\n",
    "        img = img.resize(rsize, PIL.Image.ANTIALIAS)\n",
    "        quad /= shrink\n",
    "        qsize /= shrink\n",
    "\n",
    "    # Crop.\n",
    "    border = max(int(np.rint(qsize * 0.1)), 3)\n",
    "    crop = (int(np.floor(min(quad[:, 0]))), int(np.floor(min(quad[:, 1]))),\n",
    "            int(np.ceil(max(quad[:, 0]))), int(np.ceil(max(quad[:, 1]))))\n",
    "    crop = (max(crop[0] - border, 0), max(crop[1] - border, 0),\n",
    "            min(crop[2] + border,\n",
    "                img.size[0]), min(crop[3] + border, img.size[1]))\n",
    "    if crop[2] - crop[0] < img.size[0] or crop[3] - crop[1] < img.size[1]:\n",
    "        img = img.crop(crop)\n",
    "        quad -= crop[0:2]\n",
    "\n",
    "    # Pad.\n",
    "    pad = (int(np.floor(min(quad[:, 0]))), int(np.floor(min(quad[:, 1]))),\n",
    "           int(np.ceil(max(quad[:, 0]))), int(np.ceil(max(quad[:, 1]))))\n",
    "    pad = (max(-pad[0] + border,\n",
    "               0), max(-pad[1] + border,\n",
    "                       0), max(pad[2] - img.size[0] + border,\n",
    "                               0), max(pad[3] - img.size[1] + border, 0))\n",
    "    if enable_padding and max(pad) > border - 4:\n",
    "        pad = np.maximum(pad, int(np.rint(qsize * 0.3)))\n",
    "        img = np.pad(np.float32(img),\n",
    "                     ((pad[1], pad[3]), (pad[0], pad[2]), (0, 0)), 'reflect')\n",
    "        h, w, _ = img.shape\n",
    "        y, x, _ = np.ogrid[:h, :w, :1]\n",
    "        mask = np.maximum(\n",
    "            1.0 -\n",
    "            np.minimum(np.float32(x) / pad[0],\n",
    "                       np.float32(w - 1 - x) / pad[2]), 1.0 -\n",
    "            np.minimum(np.float32(y) / pad[1],\n",
    "                       np.float32(h - 1 - y) / pad[3]))\n",
    "        blur = qsize * 0.02\n",
    "        img += (scipy.ndimage.gaussian_filter(img, [blur, blur, 0]) -\n",
    "                img) * np.clip(mask * 3.0 + 1.0, 0.0, 1.0)\n",
    "        img += (np.median(img, axis=(0, 1)) - img) * np.clip(mask, 0.0, 1.0)\n",
    "        img = PIL.Image.fromarray(np.uint8(np.clip(np.rint(img), 0, 255)),\n",
    "                                  'RGB')\n",
    "        quad += pad[:2]\n",
    "\n",
    "    # Transform.\n",
    "    img = img.transform((transform_size, transform_size), PIL.Image.QUAD,\n",
    "                        (quad + 0.5).flatten(), PIL.Image.BILINEAR)\n",
    "    if output_size < transform_size:\n",
    "        img = img.resize((output_size, output_size), PIL.Image.ANTIALIAS)\n",
    "\n",
    "    # Save aligned image.\n",
    "    img.save(dst_file, 'PNG')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843d70d6-6dec-46ca-8c7b-c95be565dcb5",
   "metadata": {},
   "source": [
    "## **ここで指定**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2942dd6-d5e2-4da7-97e4-71a4cb5d950a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cached\n",
      "cached\n",
      "total img files 33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                     | 0/33 [00:00<?, ?it/s]C:\\Users\\tsj_g\\AppData\\Local\\Temp\\ipykernel_13356\\1339783763.py:100: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
      "  img = img.resize((output_size, output_size), PIL.Image.ANTIALIAS)\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 33/33 [00:57<00:00,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output aligned images at: imgs_align\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "landmarks_model_path = unpack_bz2(\n",
    "    get_file(\n",
    "        'http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2',\n",
    "        'temp/shape_predictor_68_face_landmarks.dat.bz2'))\n",
    "\n",
    "# alignしたい画像のフォルダ\n",
    "RAW_IMAGES_DIR = \"imgs\"\n",
    "# alignした画像の保存先\n",
    "ALIGNED_IMAGES_DIR = \"imgs_align\"\n",
    "\n",
    "if not osp.exists(ALIGNED_IMAGES_DIR): os.makedirs(ALIGNED_IMAGES_DIR)\n",
    "\n",
    "files = os.listdir(RAW_IMAGES_DIR)\n",
    "num_files = len(files)\n",
    "print(f'total img files {num_files}')\n",
    "landmarks_detector = LandmarksDetector(landmarks_model_path)\n",
    "with tqdm(total=num_files) as progress:\n",
    "    for img_name in files:\n",
    "        raw_img_path = os.path.join(RAW_IMAGES_DIR, img_name)\n",
    "        for i, face_landmarks in enumerate(\n",
    "                landmarks_detector.get_landmarks(raw_img_path),\n",
    "                start=1):\n",
    "            if i == 1:\n",
    "                face_img_name = '%s.png' % (os.path.splitext(img_name)[0])\n",
    "            else:\n",
    "                face_img_name = '%s_%02d.png' % (os.path.splitext(img_name)[0], i)\n",
    "            aligned_face_path = os.path.join(ALIGNED_IMAGES_DIR, face_img_name)\n",
    "            if os.path.exists(aligned_face_path):\n",
    "                continue\n",
    "            image_align(raw_img_path, aligned_face_path, face_landmarks, output_size=256)\n",
    "            # work_landmark(raw_img_path, img_name, face_landmarks)\n",
    "        progress.update()\n",
    "\n",
    "print(f\"output aligned images at: {ALIGNED_IMAGES_DIR}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
